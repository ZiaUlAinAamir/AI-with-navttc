{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7494398-1a7f-4a5e-9443-72a4395187f9",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6203e80-fb57-4b3b-90e6-e9094bfd0a9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 2\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m: LogisticRegression(),\n\u001b[0;32m      3\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-Nearest Neighbors (k-NN)\u001b[39m\u001b[38;5;124m\"\u001b[39m: KNeighborsClassifier(),\n\u001b[0;32m      4\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupport Vector Machine (SVM)\u001b[39m\u001b[38;5;124m\"\u001b[39m: SVC(),\n\u001b[0;32m      5\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree\u001b[39m\u001b[38;5;124m\"\u001b[39m: DecisionTreeClassifier(),\n\u001b[0;32m      6\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: RandomForestClassifier(),\n\u001b[0;32m      7\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient Boosting Machines (GBM)\u001b[39m\u001b[38;5;124m\"\u001b[39m: GradientBoostingClassifier(),\n\u001b[0;32m      8\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdaBoost (Adaptive Boosting)\u001b[39m\u001b[38;5;124m\"\u001b[39m: AdaBoostClassifier(),\n\u001b[0;32m      9\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGaussian Naive Bayes\u001b[39m\u001b[38;5;124m\"\u001b[39m: GaussianNB(),\n\u001b[0;32m     10\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultinomial Naive Bayes\u001b[39m\u001b[38;5;124m\"\u001b[39m: MultinomialNB(),\n\u001b[0;32m     11\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBernoulli Naive Bayes\u001b[39m\u001b[38;5;124m\"\u001b[39m: BernoulliNB(),\n\u001b[0;32m     12\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeural Networks\u001b[39m\u001b[38;5;124m\"\u001b[39m: MLPClassifier(),\n\u001b[0;32m     13\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinear Discriminant Analysis (LDA)\u001b[39m\u001b[38;5;124m\"\u001b[39m: LinearDiscriminantAnalysis(),\n\u001b[0;32m     14\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuadratic Discriminant Analysis (QDA)\u001b[39m\u001b[38;5;124m\"\u001b[39m: QuadraticDiscriminantAnalysis(),\n\u001b[0;32m     15\u001b[0m }\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Evaluate each model\u001b[39;00m\n\u001b[0;32m     17\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "models = {\n",
    " \"Logistic Regression\": LogisticRegression(),\n",
    " \"k-Nearest Neighbors (k-NN)\": KNeighborsClassifier(),\n",
    " \"Support Vector Machine (SVM)\": SVC(),\n",
    " \"Decision Tree\": DecisionTreeClassifier(),\n",
    " \"Random Forest\": RandomForestClassifier(),\n",
    " \"Gradient Boosting Machines (GBM)\": GradientBoostingClassifier(),\n",
    " \"AdaBoost (Adaptive Boosting)\": AdaBoostClassifier(),\n",
    " \"Gaussian Naive Bayes\": GaussianNB(),\n",
    " \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    " \"Bernoulli Naive Bayes\": BernoulliNB(),\n",
    " \"Neural Networks\": MLPClassifier(),\n",
    " \"Linear Discriminant Analysis (LDA)\": LinearDiscriminantAnalysis(),\n",
    " \"Quadratic Discriminant Analysis (QDA)\": QuadraticDiscriminantAnalysis(),\n",
    "}\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    " model.fit(X_train, y_train)\n",
    " y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5fbece-c361-46a8-b5b2-8b06db2b4ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    " accuracy = accuracy_score(y_test, y_pred)\n",
    " precision = precision_score(y_test, y_pred, average='weighted')\n",
    " recall = recall_score(y_test, y_pred, average='weighted')\n",
    " f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    " results[name] = {\n",
    " \"Accuracy\": accuracy,\n",
    " \"Precision\": precision,\n",
    " \"Recall\": recall,\n",
    " \"F1 Score\": f1\n",
    " }\n",
    "# Visualization\n",
    "model_names = list(results.keys())\n",
    "accuracy_scores = [results[model]['Accuracy'] for model in model_names]\n",
    "f1_scores = [results[model]['F1 Score'] for model in model_names]\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "bars_accuracy = plt.bar(model_names, accuracy_scores, color='skyblue', edgecolor='k')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Classification Models')\n",
    "# Highlight the best model for Accuracy\n",
    "best_accuracy_idx = np.argmax(accuracy_scores)\n",
    "bars_accuracy[best_accuracy_idx].set_color('orange')\n",
    "plt.text(best_accuracy_idx, accuracy_scores[best_accuracy_idx] + 0.02, 'Best Model')\n",
    "# Plot F1 Score\n",
    "plt.subplot(1, 2, 2)\n",
    "bars_f1 = plt.bar(model_names, f1_scores, color='lightgreen', edgecolor='k')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score for Classification Models')\n",
    "# Highlight the best model for F1 Score\n",
    "best_f1_idx = np.argmax(f1_scores)\n",
    "bars_f1[best_f1_idx].set_color('orange')\n",
    "plt.text(best_f1_idx, f1_scores[best_f1_idx] + 0.02, 'Best Model', ha='center', color='red')\n",
    "# Show plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef265ace-fa03-4b6d-a21f-0a4518b05db2",
   "metadata": {},
   "source": [
    " # Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1397a57e-4341-48f3-a59b-9d8b9c499dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "models = {\n",
    " \"Linear Regression\": LinearRegression(),\n",
    " \"Ridge Regression\": Ridge(),\n",
    " \"Lasso Regression\": Lasso(),\n",
    " \"Polynomial Regression\": PolynomialFeatures(), # Note: PolynomialFeatures is n\n",
    " \"Support Vector Regression (SVR)\": SVR(),\n",
    " \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
    " \"Random Forest Regressor\": RandomForestRegressor(),\n",
    " \"Gradient Boosting Regressor\": GradientBoostingRegressor(),\n",
    " \"AdaBoost Regressor\": AdaBoostRegressor(),\n",
    " \"k-Nearest Neighbors Regressor (k-NN)\": KNeighborsRegressor(),\n",
    "}\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    " model.fit(X_train, y_train)\n",
    " y_pred = model.predict(X_test)\n",
    " mse = mean_squared_error(y_test, y_pred)\n",
    " r2 = r2_score(y_test, y_pred)\n",
    " results[name] = {\n",
    " \"Mean Squared Error\": mse,\n",
    " \"R^2 Score\": r2\n",
    " }\n",
    "\n",
    "\n",
    "# Extract model names\n",
    "models = list(results.keys())\n",
    "# Extract MSE and R^2 Scores\n",
    "mse_values = [results[model]['Mean Squared Error'] for model in models]\n",
    "r2_values = [results[model]['R^2 Score'] for model in models]\n",
    "# Find the best models\n",
    "best_mse_idx = np.argmin(mse_values)\n",
    "best_r2_idx = np.argmax(r2_values)\n",
    "# Plot MSE\n",
    "plt.figure(figsize=(14, 6))\n",
    "# Bar plot for Mean Squared Error\n",
    "plt.subplot(1, 2, 1)\n",
    "bars = plt.bar(models, mse_values, color='skyblue', edgecolor='k')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Mean Squared Error for Regression Models')\n",
    "# Highlight the best model for MSE\n",
    "bars[best_mse_idx].set_color('orange')\n",
    "plt.text(best_mse_idx, mse_values[best_mse_idx] + 500, 'Best Model', ha='center', c\n",
    "# Plot R^2 Score\n",
    "plt.subplot(1, 2, 2)\n",
    "bars_r2 = plt.bar(models, r2_values, color='lightgreen', edgecolor='k')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('R^2 Score')\n",
    "plt.title('R^2 Score for Regression Models')\n",
    "# Highlight the best model for R^2 Score\n",
    "bars_r2[best_r2_idx].set_color('orange')\n",
    "plt.text(best_r2_idx, r2_values[best_r2_idx] + 0.05, 'Best Model', ha='center', col\n",
    "# Show plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be804a7c-569c-4ca7-a440-a64051303415",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab06f03-4333-4d22-a51b-9922f1e33ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, MeanShift, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define clustering models\n",
    "clustering_models = {\n",
    "    \"KMeans\": KMeans(),\n",
    "    \"DBSCAN\": DBSCAN(),\n",
    "    \"Agglomerative Clustering\": AgglomerativeClustering(),\n",
    "    \"Mean Shift\": MeanShift(),\n",
    "    \"Spectral Clustering\": SpectralClustering(),\n",
    "    \"Gaussian Mixture Model (GMM)\": GaussianMixture(),\n",
    "}\n",
    "\n",
    "# Note: StandardScaler is typically used to scale features before applying clustering algorithms, \n",
    "# but it is not a clustering model itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a752dc9-c6ab-4bb4-bfe3-f1ae19938e49",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f529771-7f0c-407c-9d98-4ead9f7bb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, NMF, FastICA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "dimensionality_reduction_models = {\n",
    " \"Principal Component Analysis (PCA)\": PCA(),\n",
    " \"Non-Negative Matrix Factorization (NMF)\": NMF(),\n",
    " \"Fast Independent Component Analysis (FastICA)\": FastICA(),\n",
    " \"Truncated Singular Value Decomposition (TruncatedSVD)\": TruncatedSVD(),\n",
    " \"t-Distributed Stochastic Neighbor Embedding (t-SNE)\": TSNE(),\n",
    " \"Isomap\": Isomap()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa88f1-79bd-4dee-9277-6079ec9159bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
